{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro to Machine Learning with Scikit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, a learning problem considers a set of n samples of data and then tries to predict properties of unknown data. If each sample is more than a single number and, for instance, a multi-dimensional entry (aka multivariate data), it is said to have several attributes or features.\n",
    "\n",
    "For those interested, we strongly suggest to follow one or several of the sickits [tutorials](https://scikit-learn.org/stable/tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic regression: \n",
    "\n",
    "$n$ samples for\n",
    "- dependent variable: $y_n$\n",
    "- explanatory variable (regressor): $x_{n,i}$ for $i\\in[1,I]$\n",
    "\n",
    "A linear regression consists in finding coefficients $a_i$ such that:\n",
    "    $$y_n \\approx \\sum_i a_{i} x_{i,n} + \\epsilon$$\n",
    "    \n",
    "Given new data points $x_{k,i}$:\n",
    "- predict $y_{k,i}$ by  $\\sum_i a_{i} x_{i,k}$\n",
    "- (or distribution of $y_{k,i}$ by  $\\sum_i a_{i} x_{i,k} + \\epsilon$)\n",
    "- interpret $a_i$: marginal effect of variable $x_{i,n}$\n",
    "\n",
    "Test:\n",
    "- properties of $\\epsilon$, $x_{i,n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning: supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n$ samples for:\n",
    "\n",
    "- data (labels, targets): $y_n$\n",
    "- *features*: $x_{n,i}$ for $i\\in[1,I]$\n",
    "\n",
    "Construct (nonlinear) model of unknown parameters $\\theta$ such that:\n",
    "\n",
    "$$y_n \\approx f(x_{1,n}..., x_{I,n};\\theta)$$\n",
    "\n",
    "The process of finding good coefficients is called \"training\" aka \"learning\".\n",
    "\n",
    "Two kinds of supervised learning depending on the kind of output. If output $y_n$ is:\n",
    "- continuous: regression\n",
    "- discrete: classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification model can be built from a regression model:\n",
    "- for binary outcomes: $c_n\\approx \\sigma(f(x_{1,n}..., x_{I,n};\\theta))$ where $\\sigma$ is the cumulative distribution of a random shock\n",
    "- for nonbinary outcomes: encode target as dichotomous variable first, then use multilogit or voting algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "y = [0, 0, 1, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = LabelBinarizer().fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning\n",
    "\n",
    "Only features $x_{n,i}$. Possible objectives:\n",
    "- create categories (clustering)\n",
    "- evaluate a distribution (density estimation)\n",
    "- reduce dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement learning\n",
    "\n",
    "Out of topic\n",
    "\n",
    "Maximize the of future discounted rewards:\n",
    "\n",
    "$$R = \\sum_{t=0}^{\\infty} \\gamma^t r_t$$\n",
    "\n",
    "by choosing actions $a$ in state $s$. Model provides probabilities of transition $P(s,s^{\\prime}|a)$ and (stochastic) rewards $R(s,s^{\\prime})$.\n",
    "\n",
    "Looks suspiciously like the problem of an economic rational agent ;-)\n",
    "\n",
    "RL: heuristics to learn optimal policy rule $a(s)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Statistical learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "- cleanup\n",
    "- normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator\n",
    "\n",
    "Scikit estimators are dealt with in the following way:\n",
    "- estimator = Estimator(**parameters)\n",
    "- estimator.fit(data) # or estimator.fit(x,y)\n",
    "- estimator.predict(testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set / test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard procedure consists in splitting a dataset into\n",
    "- a training set used to determine coefficients\n",
    "- a test set used to measure prediction\n",
    "\n",
    "Training set is typically a random fraction of the whole sample (e.g. 10%)\n",
    "\n",
    "\n",
    "Different accuracy measures can be used inside and outside the training set, to check for fitness (outside), and avoid overfitting (inside).\n",
    "\n",
    "![](./Precisionrecall.png)\n",
    "\n",
    "All estimators expose a `.score()` method for that purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the validity of a given model, we can use split the data\n",
    "into several $10%$ subsets. Then for each subsect (fold)\n",
    "train the model on remaining data and test on the fold.\n",
    "\n",
    "This is called Kfold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selection of the random samples can be done\n",
    "#\n",
    "# using numpy:\n",
    "# np.split, np.random.permutation\n",
    "#\n",
    "# with scikit:\n",
    "# sklearn.model_selection.KFold\n",
    "\n",
    "# kfold cross-validation can also be done with\n",
    "# sklearn.model_selection.cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "\n",
    "Remark: many algorithms amount to the optimization of a loss function\n",
    "\n",
    "- Classification/regression\n",
    "\n",
    "    - k nearest neighbors classifier\n",
    "    - support vector machines\n",
    "        - linear\n",
    "        - plynomial\n",
    "        - rbf    \n",
    "    - sparse regressions\n",
    "        - lasso\n",
    "        - ridge\n",
    "    - Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clustering / dim reduction\n",
    "    - k-means\n",
    "    - PCA\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the [map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Many classifiers](many_classifiers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sparse regressions\n",
    "\n",
    "- lasso (shrinks)\n",
    "\n",
    "$$\\min_{\\beta} \\frac{1}{N} || y- X\\beta||^2_2+\\lambda ||\\beta||_1$$\n",
    "\n",
    "- ridge (sparsifies, sets coeffs to 0):\n",
    "\n",
    "$$\\min_{\\beta} \\frac{1}{N} || y- X\\beta||^2_2+\\lambda ||\\beta||_2$$\n",
    "\n",
    "- elastic net:\n",
    "\n",
    "$$\\min_{\\beta} \\frac{1}{N} || y- X\\beta||^2_2 + \\lambda_1 ||\\beta||_1 + \\lambda_2 ||\\beta||_2$$\n",
    "\n",
    "Formulation as an objective to minimize is typical of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer on neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... time allowing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
